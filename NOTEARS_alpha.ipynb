{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bf82444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import icd10\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "from causalnex.structure import StructureModel\n",
    "warnings.filterwarnings(\"ignore\")  # silence warnings\n",
    "\n",
    "from IPython.display import Image\n",
    "from causalnex.plots import plot_structure, NODE_STYLE, EDGE_STYLE\n",
    "\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from zepid import RiskRatio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d7774a",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb5e7ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_table('entire_data_participant.tsv')\n",
    "data = data.rename(columns={\"p41270\": \"Diagnoses - ICD10\", \"p31\": \"Sex\", 'p34': 'Year of birth'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "574a4838",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['icd'] = data ['Diagnoses - ICD10'].str.split('|')\n",
    "data['age'] = 2023 - data['Year of birth']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "data['gender'] = le.fit_transform(data['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b60dc49e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_icd = data[data['icd'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8ba74bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no = data[data['icd'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8347cad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_pn =  list(data_icd['icd'])\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(fp_pn).transform(fp_pn)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "df = df.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30c6bf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(0, index=np.arange(len(data_no)), columns=df.columns)\n",
    "df = pd.concat([df,d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8ff369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = df.describe().T\n",
    "#top = n.sort_values(by = 'mean', ascending = False)[:500]\n",
    "top = n[n['mean'] >= 0.005]\n",
    "test_top = df[top.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecc26057",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_top = df[top.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4d6fbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_top = test_top.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23ef7a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data_icd,data_no]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "820e67ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([test_top.iloc[:,1:], data[['age','gender']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "462f60e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = np.where(df['age'] > 65, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a83c5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(how='any',axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a2313c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gold = ['F03','I10','E78.0','N17.9','J22','F41.9','I25.9','N18.3','E66.9','K59','J22','N18.9','N18.3',\\\n",
    "#        'I67.8','G20','I67.9']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f0e8f4",
   "metadata": {},
   "source": [
    "# NOTEARS_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd3ce96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as slin\n",
    "import scipy.optimize as sopt\n",
    "from scipy.special import expit as sigmoid\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "def notears_linear(X, lambda1, loss_type, max_iter=100, h_tol=1e-8, rho_max=1e+16, w_threshold=0.0):\n",
    "    \"\"\"Solve min_W L(W; X) + lambda1 ‖W‖_1 s.t. h(W) = 0 using augmented Lagrangian.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): [n, d] sample matrix\n",
    "        lambda1 (float): l1 penalty parameter\n",
    "        loss_type (str): l2, logistic, poisson\n",
    "        max_iter (int): max num of dual ascent steps\n",
    "        h_tol (float): exit if |h(w_est)| <= htol\n",
    "        rho_max (float): exit if rho >= rho_max\n",
    "        w_threshold (float): drop edge if |weight| < threshold\n",
    "\n",
    "    Returns:\n",
    "        W_est (np.ndarray): [d, d] estimated DAG\n",
    "    \"\"\"\n",
    "    def _loss(W):\n",
    "        \"\"\"Evaluate value and gradient of loss.\"\"\"\n",
    "        M = X @ W\n",
    "        if loss_type == 'l2':\n",
    "            alpha = 0\n",
    "            Y = 1 - X\n",
    "            R = X *(X - M) + alpha * Y * (X - M)\n",
    "            #R = X - M\n",
    "            loss = 0.5 / X.shape[0] * (R ** 2).sum()\n",
    "            G_loss = - 1.0 / X.shape[0] * X.T @ R\n",
    "        elif loss_type == 'logistic':\n",
    "            loss = 1.0 / X.shape[0] * (np.logaddexp(0, M) - X * M).sum()\n",
    "            G_loss = 1.0 / X.shape[0] * X.T @ (sigmoid(M) - X)\n",
    "        elif loss_type == 'poisson':\n",
    "            S = np.exp(M)\n",
    "            loss = 1.0 / X.shape[0] * (S - X * M).sum()\n",
    "            G_loss = 1.0 / X.shape[0] * X.T @ (S - X)\n",
    "        else:\n",
    "            raise ValueError('unknown loss type')\n",
    "        return loss, G_loss\n",
    "\n",
    "    def _h(W):\n",
    "        \"\"\"Evaluate value and gradient of acyclicity constraint.\"\"\"\n",
    "        E = slin.expm(W * W)  # (Zheng et al. 2018)\n",
    "        h = np.trace(E) - d\n",
    "        #     # A different formulation, slightly faster at the cost of numerical stability\n",
    "        #     M = np.eye(d) + W * W / d  # (Yu et al. 2019)\n",
    "        #     E = np.linalg.matrix_power(M, d - 1)\n",
    "        #     h = (E.T * M).sum() - d\n",
    "        G_h = E.T * W * 2\n",
    "        return h, G_h\n",
    "\n",
    "    def _adj(w):\n",
    "        \"\"\"Convert doubled variables ([2 d^2] array) back to original variables ([d, d] matrix).\"\"\"\n",
    "        return (w[:d * d] - w[d * d:]).reshape([d, d])\n",
    "\n",
    "    def _func(w):\n",
    "        \"\"\"Evaluate value and gradient of augmented Lagrangian for doubled variables ([2 d^2] array).\"\"\"\n",
    "        W = _adj(w)\n",
    "        loss, G_loss = _loss(W)\n",
    "        h, G_h = _h(W)\n",
    "        obj = loss + 0.5 * rho * h * h + alpha * h + lambda1 * w.sum()\n",
    "        G_smooth = G_loss + (rho * h + alpha) * G_h\n",
    "        g_obj = np.concatenate((G_smooth + lambda1, - G_smooth + lambda1), axis=None)\n",
    "        return obj, g_obj\n",
    "\n",
    "    n, d = X.shape\n",
    "    w_est, rho, alpha, h = np.zeros(2 * d * d), 1.0, 0.0, np.inf  # double w_est into (w_pos, w_neg)\n",
    "    bnds = [(0, 0) if i == j else (0, None) for _ in range(2) for i in range(d) for j in range(d)]\n",
    "    if loss_type == 'l2':\n",
    "        X = X - np.mean(X, axis=0, keepdims=True)\n",
    "    for iter in range(max_iter):\n",
    "        print(iter)\n",
    "        w_new, h_new = None, None\n",
    "        while rho < rho_max:\n",
    "            sol = sopt.minimize(_func, w_est, method='L-BFGS-B', jac=True, bounds=bnds,\\\n",
    "                                options={'disp': True,'eps':1e-40,'maxls':40})\n",
    "            #sol = sopt.minimize(_func, w_est, method='BFGS', jac=True, bounds=bnds)\n",
    "            #sol = sopt.fmin_l_bfgs_b(_func, w_est,approx_grad=True, bounds=[(1e-8, 0.5)], factr=1e02, pgtol=1e-05, epsilon=1e-08)\n",
    "\n",
    "            w_new = sol.x\n",
    "            h_new, _ = _h(_adj(w_new))\n",
    "            if h_new > 0.25 * h:\n",
    "                rho *= 10\n",
    "            else:\n",
    "                break\n",
    "        w_est, h = w_new, h_new\n",
    "        W_est = _adj(w_est)\n",
    "        print(np.sum(W_est))\n",
    "        alpha += rho * h\n",
    "        if h <= h_tol or rho >= rho_max:\n",
    "            break\n",
    "    W_est = _adj(w_est)\n",
    "    return W_est\n",
    "\n",
    "def read_file(data_dir, sep=\",\"):\n",
    "    with open(data_dir, \"r\") as f:\n",
    "        data = f.read().strip().split(\"\\n\")\n",
    "    data = [i.split(sep) for i in data]\n",
    "    return np.array(data).astype(float)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # from tools import utils\n",
    "    #\n",
    "    # utils.set_random_seed(1)\n",
    "    #\n",
    "    # n, d, s0, graph_type, sem_type = 20000, 100, 20, 'SF', 'gauss' # sem_type: gauss, logistic\n",
    "    # B_true = utils.simulate_dag(d, s0, graph_type)\n",
    "    # print(B_true.sum())\n",
    "    # W_true = B_true\n",
    "    # #W_true = utils.simulate_parameter(B_true) # why should we simulate parameters?\n",
    "    # #np.savetxt('W_true.csv', W_true, delimiter=',')\n",
    "    #\n",
    "    # X = utils.simulate_linear_sem(W_true, n, sem_type)\n",
    "    #\n",
    "    # X2 = utils.simulate_linear_sem(W_true, n, sem_type)\n",
    "    # #X = utils.simulate_nonlinear_sem(W_true, n, sem_type)\n",
    "    # #np.savetxt('X.csv', X, delimiter=',')\n",
    "    #\n",
    "    # start_time = time.time()\n",
    "    #\n",
    "    # W_est = notears_linear(X, lambda1=0., loss_type='l2', max_iter=10)\n",
    "    #\n",
    "    # end_time = time.time()\n",
    "    # print(\"time: {}\".format(end_time-start_time))\n",
    "    #\n",
    "    # print(\"W_est.sum: {}\".format(W_est.sum()))\n",
    "    # W_est[np.abs(W_est) < 0.1] = 0\n",
    "    # assert utils.is_dag(W_est)\n",
    "    # #np.savetxt('W_est.csv', W_est, delimiter=',')\n",
    "    # acc = utils.count_accuracy(B_true, W_est != 0)\n",
    "    # print(W_est.sum())\n",
    "    # print(acc)\n",
    "    ###############################################################\n",
    "\n",
    "    X2 = df.to_numpy()\n",
    "    W_est = notears_linear(X2, lambda1=0., loss_type='l2', max_iter=5)\n",
    "    print(\"W_est: {}\".format(W_est))\n",
    "\n",
    "    import pandas as pd\n",
    "    W_out = pd.DataFrame(W_est)\n",
    "    W_out.to_csv('entire_biobank_10_encode_age_max_2.csv')\n",
    "    # X = read_file(\"X_mimic.txt\", \" \")\n",
    "    # W_est = notears_linear(X, lambda1=0., loss_type='l2', max_iter=100, w_threshold=0.)\n",
    "    print(W_est)\n",
    "\n",
    "    ##############################\n",
    "    # import pandas as pd\n",
    "    # mimic3 = read_file(\"DIAGNOSES_ICD.csv\")\n",
    "    # mimic3 = pd.DataFrame(mimic3[1:], columns=[\"ROW_ID\", \"SUBJECT_ID\", \"HADM_ID\", \"SEQ_NUM\", \"ICD9_CODE\"])\n",
    "    # patients = mimic3['SUBJECT_ID'].to_list()\n",
    "    # patients = list(set(patients))\n",
    "    # print(len(patients))\n",
    "    # icd = read_file(\"icd.csv\")\n",
    "    # icd = np.array(icd).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73036225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
